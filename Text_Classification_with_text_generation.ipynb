{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification with text generation.ipynb ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzcHopy0BxQx2Efxtk7/Mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuLiu83/Practical-business-case-code-demo/blob/main/Text_Classification_with_text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-aQD72-eAJA"
      },
      "source": [
        "The task is to create a text classification model using LSTM NN to predict whether or not an email is spam. A text generation technique is also being implemented here to deal with the data imbalance challange."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5U0onT7eDjJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwXHJIn2eFTC"
      },
      "source": [
        "### Load and Observe Data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxEOOJwWLpB2",
        "outputId": "bf0a4c49-b06c-4065-dbec-63799c385057",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PeT474c7KtG",
        "outputId": "34aeccfe-e5c3-4f35-eb5c-98bbfe607430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# check system readiness\n",
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 17 14:57:25 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    32W / 250W |   2445MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkGuzu8xOoy"
      },
      "source": [
        "Check file counts in the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Z_xD6fwqNg"
      },
      "source": [
        "cd /content/drive/My Drive/Data/ClassificationData/spam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZkO1CV3w4ka",
        "outputId": "db67ea3f-b5b8-4395-a8ce-95cacd91789e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls -1 |grep spam.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kVSMe9kwqWb"
      },
      "source": [
        "cd /content/drive/My Drive/Data/ClassificationData/ham"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqFTzvp_xG-Y",
        "outputId": "aa30a8c9-c7f8-45aa-ba9a-36c4c06ab47e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ls -1 |grep ham.txt | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt8zEKcuxsUJ"
      },
      "source": [
        "Load and combine text and label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwnSFCCgXjk4"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from random import shuffle\n",
        "def pre_process_data(filepath):\n",
        "  positive_path = os.path.join(filepath, 'spam')\n",
        "  negative_path = os.path.join(filepath, 'ham')\n",
        "  pos_label = 1\n",
        "  neg_label = 0\n",
        "  dataset = []\n",
        "\n",
        "  for filename in glob.glob(os.path.join(positive_path, '*.txt')):\n",
        "    with open(filename, 'r', encoding='utf-8',\n",
        "                 errors='ignore') as f:\n",
        "      dataset.append((pos_label, f.read()))\n",
        "\n",
        "  for filename in glob.glob(os.path.join(negative_path, '*.txt')):\n",
        "    with open(filename, 'r', encoding='utf-8',\n",
        "                 errors='ignore') as f:\n",
        "      dataset.append((neg_label, f.read()))\n",
        "\n",
        "  shuffle(dataset)\n",
        "\n",
        "  return dataset\n",
        "\n",
        "dataset = pre_process_data(\"/content/drive/My Drive/Data/ClassificationData\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oidvmi8zphX0",
        "outputId": "74352d73-a689-4ed5-941d-679226ed2dc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# Visually check data\n",
        "dataset[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1,\n",
              "  \"Subject: eshopping at our chemist - site helps you sav a lot on rneds .\\nflnd a better way to sav on medicals . at our chemist - site , you have the\\nbestselections on quality rneds .\\nchoose our store for a range of quality medicaments on pain , swelling ,\\nereection dysfunction , highcholesterol , obesity , stress , musclerelaxant and\\nman ' s care .\\nour company cooperates with the most experienced logistic companies\\nto ensure timely shipment . , check this superssale on quality rneds at our\\ncyber store .\\nbrowse the affordable ones\\nat cyber chemist .\\nat our store , customers can gget their case profile reviewed for ffree .\\nshopping for rneds is much easier . at your chemist - site , i can select from\\nthese top - selling rneds . and best of all , they are much , much ccheaper than\\nthose sold at the local pharrnacy . and also thank you for providing timely\\nservices . - - tina d . in la\\nhave mentioned . . . . we closely akin t\\nrest ; but what they called ' o reality ; but stilli\\nll , ( returning t has its harmonious e xplanation here on earth ,\\nwhile reality of\\nthe when 1 raphael ' smerry li the 35 one fe ' disappeared before hi\\n\"),\n",
              " (1,\n",
              "  'Subject: attn : security update from citibank msgid # 92379245\\ncitibank ( r )\\ndear citibank customer :\\nrecently there have been a large number computer terrorist attacks over our\\ndatabase server . in order to safeguard your account , we require that you update\\nyour citibank atm / debit card pin .\\nthis update is requested of you as a precautionary measure against fraud . please\\nnote that we have no particular indications that your details have been compromised\\nin any way .\\nthis process is mandatory , and if not completed within the nearest time your\\naccount may be subject to temporary suspension .\\nplease make sure you have your citibank atm / debit card and your login details\\nat hand .\\nto securely update your citibank atm / debit card pin please go to :\\ncustomer verification\\nform\\nplease note that this update applies to your citibank atm / debit card - which\\nis linked directly to your checking account , not citibank credit cards .\\nthank you for your prompt attention to this matter and thank you for using\\ncitibank !\\nregards ,\\ncustomer support msgid # 92379245\\n( c ) 2004 citibank . citibank , n . a . , citibank , f . s . b . ,\\ncitibank ( west ) , fsb . member fdic . citibank and arc\\ndesign is a registered service mark of citicorp .\\n'),\n",
              " (1,\n",
              "  'Subject: re [ 18 ]\\nrobert blake we might . . . in 1863 capital punishmentopen directory alabama'),\n",
              " (0,\n",
              "  \"Subject: re : interactive open season test packages\\nthanks ! also , i ' m forwarding this to michelle .\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by lindy donoho / et & s / enron on 07 / 19 / 2000\\n02 : 50 pm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nfrom : toby kuehl 07 / 19 / 2000 01 : 41 pm\\nto : lindy donoho / et & s / enron @ enron\\ncc :\\nsubject : re : interactive open season test packages\\noops ! forgot you on the list !\\n- - - - - - - - - - - - - - - - - - - - - - forwarded by toby kuehl / et & s / enron on 07 / 19 / 2000 01 : 42\\npm - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nfrom : toby kuehl 07 / 19 / 2000 01 : 40 pm\\nto : lorraine lindberg / et & s / enron @ enron , tk lohman / et & s / enron @ enron , christine\\nstokes / et & s / enron @ enron , jeffery fawcett / et & s / enron @ enron\\ncc : richard abramowicz / et & s / enron @ enron , girish kaimal / ots / enron @ enron ,\\nsheila nacey / et & s / enron @ enron\\nsubject : re : interactive open season test packages\\ndoes your testing seem to be going ok ? i haven ' t heard from anyone yet .\\nlet rich or myself know . . . .\\ntoby\\nrichard abramowicz\\n07 / 19 / 2000 08 : 27 am\\nto : jeffery fawcett / et & s / enron @ enron , tk lohman / et & s / enron @ enron , christine\\nstokes / et & s / enron @ enron , lorraine lindberg / et & s / enron @ enron , girish\\nkaimal / ots / enron @ enron\\ncc :\\nsubject : interactive open season test packages\\nthe interactive open season test packages are loaded on ios . ets . enron . com .\\nwe put in the change where shippers must bid on the full capacity of the\\npackage , no partial capacities are allowed . even though the package with the\\n3 month term has been loaded , we can remove it if we need to . the following\\ntest user have been set up for testing .\\nuser id password package 15 volume package 16 volume\\ntestl userl 20000 0\\ntest 2 user 2 20000 0\\ntest 3 user 3 20000 0\\ntest 4 user 4 20000 0\\ntest 5 user 5 20000 49000\\ntest 6 user 6 20000 49000\\ntest 7 user 7 0 49000\\ntest 8 user 8 0 49000\\ntest 9 user 9 0 49000\\ntestl 0 userl 0 0 49000\\nthis iosadmin password is k 97 hyt 86\\nbecause the ios application hasn ' t been thoroughly used since february of\\n1999 , it is very important to do this testing . i you need us to reset the\\nbids or the end time , or if you notice any problems while testing , please\\npage us at ( 877 ) 497 - 3254 .\"),\n",
              " (1,\n",
              "  'Subject: inte [ r ] est : $ 630995\\ndear applicant ,\\nyour application was processed and approved . you are eligible for $ 400 , 000 with a 2 . 1 % rate .\\nplease verify your information here : http : / / www . bellmarketing 4 us . com / green / m 79 a\\nwe look forward to hearing from you .\\njackie odd , account manager\\nbell marketing\\n4206 central avenue\\ncolumbus , oh 43085\\nnot interested - > http : / / www . bellmarketing 4 us . com / green / stop . html')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUTsyATI0tn"
      },
      "source": [
        "# save the combined file\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/dataset.data', 'wb') as file:\n",
        "  pickle.dump(dataset, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0w5p5tMpgVQ"
      },
      "source": [
        "# load the saved combined file\n",
        "import pickle\n",
        "\n",
        "with open('/content/drive/My Drive/dataset.data', 'rb') as file:\n",
        "    # read the data as binary data stream\n",
        "    dataset = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr0Fw649f2Oa"
      },
      "source": [
        "### Data Processing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8R7JE6agaoN"
      },
      "source": [
        "Prepare X (input) and Y (output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMOh6IctRhaY"
      },
      "source": [
        "X=[text[1] for text in dataset]\n",
        "Y=[text[0] for text in dataset]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmDGda9W8bg4"
      },
      "source": [
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def Token(text_list):\n",
        "  X_Cleaned=[]\n",
        "  for text in X:\n",
        "    pattern = r'(Subject: )'   # Remove the string shown at beginning of every text\n",
        "    processed_text=re.sub(pattern, '', text)\n",
        "    X_Cleaned.append(processed_text)\n",
        "  tokenizer=Tokenizer()\n",
        "  tokenizer.fit_on_texts(X_Cleaned)\n",
        "  X_Tokenized=tokenizer.texts_to_sequences(X_Cleaned)\n",
        "\n",
        "  \n",
        "  return X_Tokenized, tokenizer.word_counts, tokenizer.word_index, tokenizer.document_count\n",
        "\n",
        "\n",
        "Token_Profile=Token(X)\n",
        "\n",
        "X_Tokenized=Token_Profile[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLBJ5H0WzYiU"
      },
      "source": [
        "# Split data for training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_Tokenized,Y, test_size = 0.15, random_state=80)\n",
        "\n",
        "y_test_array=np.asarray(Y_test) # compared againt the test prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMaMj6QJgVh6"
      },
      "source": [
        "The ham and spam classes are highly imbalanced (1:3), the next step is to balance the two classes to about the same length. Code below generates a list of new ham texts based on original ham texts. The newly created and original ham messages will then be combined to create a balanced dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RE0BchRsGWd",
        "outputId": "eb002a65-3c35-4bcb-c8ae-92838068ca38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Select ham cases\n",
        "idxh = np.argwhere(np.array(Y_train)==0)\n",
        "x_train0 = np.array(X_train)[idxh]\n",
        "y_train0 = np.array(Y_train)[idxh]\n",
        "\n",
        "# Select spam cases\n",
        "idxs = np.argwhere(np.array(Y_train)==1)\n",
        "x_train_Spam = np.array(X_train)[idxs]\n",
        "y_train_Spam = np.array(Y_train)[idxs]\n",
        "\n",
        "\n",
        "Ham_train_len=len(x_train0)\n",
        "Spam_train_len=len(x_train_Spam)\n",
        "print('Train Ham: {};'.format(Ham_train_len), 'Train Spam: {}'.format(Spam_train_len))\n",
        "\n",
        "Ratio=len(x_train_Spam)/len(x_train0)\n",
        "print('Spam files are {:.0f} times more than Ham files'.format(Ratio) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Ham: 1262; Train Spam: 3837\n",
            "Spam files are 3 times more than Ham files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4p6DT0xlniI"
      },
      "source": [
        "#### Prepare data for text generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zpmprw00SEa"
      },
      "source": [
        "# reverse the index so we can search the word by index\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdhMPbGwsWBF"
      },
      "source": [
        "# the model will generate letters/chars instead of words, find all unique chars\n",
        "\n",
        "letter_list = []\n",
        "for word in list(word_index.keys()):\n",
        "  for letter in word:\n",
        "    if letter not in letter_list:\n",
        "      letter_list.append(letter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHNzI4EosWay"
      },
      "source": [
        "# assign each letter/char an index\n",
        "\n",
        "val = list(range(len(letter_list)+1)) \n",
        "letter_index = dict(zip(letter_list, val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWfzkiYlsWrQ",
        "outputId": "48003c5c-6480-438e-e327-e3cc25cf34e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# To put all reviews in the same list as list elements before feeding into the model\n",
        "\n",
        "master_holder = [[]]\n",
        "\n",
        "for record in x_train0:\n",
        "  holder = []\n",
        "  for idx in record[0]:  # record in a 1D array, record[0] is a list. \n",
        "    \n",
        "    if idx in reverse_word_index: \n",
        "      holder.append(reverse_word_index[idx]) # search the word using index\n",
        "    else:\n",
        "      holder.append('UNK')\n",
        "\n",
        "  master_holder.append(holder)\n",
        "master_holder.pop(0) # remove empty space at beginning\n",
        "\n",
        "# put all records in a list\n",
        "master_list=[]\n",
        "master_list = [(' '.join(master_holder[idx])) for idx in range(len(master_holder))]\n",
        "\n",
        "print(len(master_list))\n",
        "print(len(master_holder))\n",
        "\n",
        "# put all elements in the list together creating a long string\n",
        "text = ' '.join(master_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1262\n",
            "1262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPW7KoDQsW1a",
        "outputId": "748f6162-8690-4cbc-b753-359954267598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# count unique letters/symbals in the text\n",
        "vocab=sorted(set(text))\n",
        "print(len(vocab))\n",
        "\n",
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "# recode each char in the text using the char index it holds. Now all the docs are recoded using char index.\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ysDCncX1cgy"
      },
      "source": [
        "# Create input and target text\n",
        "import tensorflow as tf\n",
        "\n",
        "# The maximum length sentence we want for a single input in characters\n",
        "seq_length = 100\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) #+1 to get both input & output length\n",
        "\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd_JlZMVsWYR",
        "outputId": "1bddf0d8-f505-41e4-a67a-ed8b8044a7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Batch size \n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTX_s-69mvNl"
      },
      "source": [
        "#### Set up text generation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuC75cJQsWVq",
        "outputId": "4832505f-b77f-4820-afdd-5121e0f5530d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "print(vocab_size)\n",
        "\n",
        "# The embedding dimension \n",
        "embedding_dim = 32\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-WJkTd-sWR5"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.GRU(rnn_units,  \n",
        "        return_sequences=True, \n",
        "        recurrent_initializer='glorot_uniform',\n",
        "        dropout=0.2,\n",
        "        recurrent_dropout=0.2,\n",
        "        stateful=True),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vb_zSIvsWP7",
        "outputId": "3d6d0803-8468-433f-eee0-abdd50dc47fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model = build_model(\n",
        "    vocab_size = len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 32)            1312      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (64, None, 1024)          3250176   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 41)            42025     \n",
            "=================================================================\n",
            "Total params: 3,293,513\n",
            "Trainable params: 3,293,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlUltwkSsWOk"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "model.compile(optimizer=tf.optimizers.Adam(), loss= loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW68aXN4sWNF"
      },
      "source": [
        "import os\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = '/content/drive/Checkpoints/training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKTv5k_SsWLC",
        "outputId": "f75459f5-f66d-410c-cdb4-85e77c84ea77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "EPOCHS=40\n",
        "history=model.fit(dataset, epochs=EPOCHS, callbacks=[EarlyStopping(monitor='loss', patience=2\n",
        "), checkpoint_callback])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "275/275 [==============================] - 43s 156ms/step - loss: 1.1381\n",
            "Epoch 2/40\n",
            "275/275 [==============================] - 43s 157ms/step - loss: 1.1372\n",
            "Epoch 3/40\n",
            "275/275 [==============================] - 43s 156ms/step - loss: 1.1349\n",
            "Epoch 4/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1320\n",
            "Epoch 5/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1306\n",
            "Epoch 6/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1291\n",
            "Epoch 7/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1272\n",
            "Epoch 8/40\n",
            "275/275 [==============================] - 42s 155ms/step - loss: 1.1251\n",
            "Epoch 9/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1246\n",
            "Epoch 10/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1231\n",
            "Epoch 11/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1220\n",
            "Epoch 12/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1209\n",
            "Epoch 13/40\n",
            "275/275 [==============================] - 43s 156ms/step - loss: 1.1208\n",
            "Epoch 14/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1196\n",
            "Epoch 15/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1185\n",
            "Epoch 16/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1176\n",
            "Epoch 17/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1168\n",
            "Epoch 18/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1156\n",
            "Epoch 19/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1151\n",
            "Epoch 20/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1145\n",
            "Epoch 21/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1135\n",
            "Epoch 22/40\n",
            "275/275 [==============================] - 42s 153ms/step - loss: 1.1128\n",
            "Epoch 23/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1127\n",
            "Epoch 24/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1114\n",
            "Epoch 25/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1114\n",
            "Epoch 26/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1111\n",
            "Epoch 27/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1103\n",
            "Epoch 28/40\n",
            "275/275 [==============================] - 43s 157ms/step - loss: 1.1100\n",
            "Epoch 29/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1100\n",
            "Epoch 30/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1098\n",
            "Epoch 31/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1089\n",
            "Epoch 32/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1086\n",
            "Epoch 33/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1078\n",
            "Epoch 34/40\n",
            "275/275 [==============================] - 42s 155ms/step - loss: 1.1075\n",
            "Epoch 35/40\n",
            "275/275 [==============================] - 43s 155ms/step - loss: 1.1077\n",
            "Epoch 36/40\n",
            "275/275 [==============================] - 42s 154ms/step - loss: 1.1087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGQtQUiSoZCQ"
      },
      "source": [
        "#### Generate new Ham messages\n",
        "\n",
        "The model generates one character a time. Load the trained model parameter and set batch_size=1 (one character a time).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwBtjrdDsWIR"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ieOqV4sV-l",
        "outputId": "0063cd0d-e435-4c8e-e7d7-b39ad8fcdd50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (1, None, 32)             1312      \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 1024)           3250176   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (1, None, 41)             42025     \n",
            "=================================================================\n",
            "Total params: 3,293,513\n",
            "Trainable params: 3,293,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjC-WV61sV7e",
        "outputId": "c9df6853-7090-497f-c643-0713efc9b931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Decide the length of generated reviews \n",
        "length_holder=[]\n",
        "for doc in master_list:\n",
        "  length_holder.append(len(doc))\n",
        "\n",
        "print('Mean: {}, Percentiles: {}'.format(int(np.mean(length_holder)), np.percentile(length_holder, [25, 50, 75])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean: 1411, Percentiles: [ 356.    872.   1708.75]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8e00-spUXI6"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  # Number of characters to generate for each message\n",
        "  num_generate = 900\n",
        "\n",
        "  # Vectorizing\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  temperature = 0.9\n",
        "\n",
        "  # Here batch size == 1 to produce one token a time\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a multinomial distribution to predict the word returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy() #=tf.multinomial()\n",
        "      \n",
        "      # the predicted word is then used as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "      \n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsFZGIyYD70M"
      },
      "source": [
        "# Find the top appearing starting char (= number of reviews we need to generate and use each of these char to generate a review. Or we can radomly sample them as the start char)\n",
        "n=int(Ham_train_len*2)\n",
        "from collections import Counter\n",
        "d=Counter(text.split())\n",
        "\n",
        "topn_start=[]\n",
        "for k, v, in d.most_common(n):\n",
        "  topn_start.append(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y61OpKivD72x",
        "outputId": "e9c22cab-0c73-474e-a7f4-dfd5d345df3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# store generated text in a list\n",
        "%%time\n",
        "from progressbar import ProgressBar\n",
        "pbar=ProgressBar()\n",
        "generated = []\n",
        "\n",
        "for start_word in pbar(topn_start):\n",
        "  generated.append(generate_text(model, start_word))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% (2524 of 2524) |####################| Elapsed Time: 5:44:55 Time:  5:44:55\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5h 44min 5s, sys: 7min 50s, total: 5h 51min 56s\n",
            "Wall time: 5h 44min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOJ4UtCvXwl6"
      },
      "source": [
        "# save generated ham text\n",
        "import pickle\n",
        "pickle_out = open(\"/content/drive/My Drive/Data/generated_ham.pickle\",\"wb\")\n",
        "pickle.dump(generated, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKiBRbXDEG4K"
      },
      "source": [
        "# load generated ham text\n",
        "import pickle\n",
        "generated = pickle.load( open( \"//content/drive/My Drive/Data/generated_ham.pickle\", \"rb\" ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZt-9LFFEG6r",
        "outputId": "8196c369-e226-4efb-c6f4-c48e14cb1ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "generated[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"thering time in our time and return to the power storage level by stan holt of contracts is guardian ' s points we canadian acquisitions 28 events coming up 28 did you just wyitten a from burlington lindy when stabilities a sng business position and options delivery handling please click ebiz home enron com cllewett users the final approval of 0 051 mw of houston factor coordinator announced 1 years ago its skills to remain price of 1 710 mmcf d 97 other pipeline el paso merchant properties in development of markets and the office of this email passed the discussion to needles this year no sponsors webmust understanding with although understanding charges that will be ready to replace the supply west at the california capacity supply silsing business units west flow capacity should be outs if you look forward to says that have a happy horidoy with corporate securing natural gas markets the \""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv43xb8uEHhc"
      },
      "source": [
        "Tokenize generated text and code them into index number same form as the x_train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFwAhIXEp_Dd"
      },
      "source": [
        "#### Combine generated ham text with original text and prepare data for model input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vd-2HQwyOdgU"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMaofXJFeEfI"
      },
      "source": [
        "# assign an index to unknown words (optional) and creat it word, index dictionary\n",
        "word_index[\"<UNK>\"] = len(Token_Profile[2])+1 # unknown\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LQj6FT1EHAj"
      },
      "source": [
        "x = np.empty((len(generated)), dtype=list)\n",
        "i = 0\n",
        "for merged_sentence in generated:\n",
        "  words = nltk.word_tokenize(''.join(merged_sentence))\n",
        "  seqs = []\n",
        "  for word in words:\n",
        "    if word in word_index:\n",
        "      seqs.append(word_index[word])\n",
        "    else:\n",
        "      seqs.append(word_index['<UNK>']) # for unknown\n",
        "\n",
        "  x[i] = seqs\n",
        "  i +=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oJRilrVEHEN"
      },
      "source": [
        "# Create labels for generated text\n",
        "y_train_generated = y_train_Spam[:len(generated)] # spam is longer than ham, so just chop from here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T4o-DFqJHBx",
        "outputId": "b4d8dbc8-bb2e-4898-eea4-74a189a9c4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Stack generated x and y\n",
        "x_train_assembled = np.concatenate((x_train_Spam, x_train0, x), axis = None)\n",
        "y_train_assembled = np.concatenate((y_train_Spam, y_train0,  y_train_generated), axis = None)\n",
        "\n",
        "print(x_train_assembled.shape,y_train_assembled.shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7623,) (7623,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79iab77fZ97s",
        "outputId": "503e0d0e-96ed-4679-f95a-6cee065868f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "x_train_assembled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([10238, 68, 191, 41, 153, 100, 5068, 41, 153, 54, 506, 467, 5068, 506, 1981, 68, 16, 9785, 68, 1152, 626, 2259, 411, 3240, 2, 33, 2220, 25, 324, 560, 411, 196, 118, 7, 173, 30, 578, 1904, 153, 7, 1150, 1968, 153, 257, 1151, 330, 117, 55, 233, 812, 47, 75, 37, 153, 578, 2083, 410, 7, 1150, 2012, 410, 45, 45, 45, 411, 2, 634, 21, 22, 66, 25, 347, 575, 411, 257, 1749, 1805, 2069, 1905, 924, 2027, 889, 893, 351, 1881, 2070, 1636, 1919, 2052, 2221, 2013, 617, 513, 1609, 1527, 430, 2103, 1882, 659, 1683, 2173, 2104, 1568, 2222, 411, 2113, 45, 560, 1528, 9, 3076, 63, 2113, 45, 560, 411, 15, 26, 2880, 626, 302, 2545, 2634, 58, 2, 348, 63]),\n",
              "       list([1145, 1609, 1981, 68, 16, 5345, 2887, 924, 5346, 144, 21, 151, 277, 4105, 62, 155, 418, 3721, 78, 1710, 2460, 208, 626, 2259, 411, 3240, 2, 33, 2220, 25, 324, 560, 411, 196, 118, 7, 173, 30, 578, 1904, 153, 7, 1150, 1968, 153, 257, 1151, 330, 117, 55, 233, 812, 47, 75, 37, 153, 578, 2083, 410, 7, 1150, 2012, 410, 45, 45, 45, 411, 2, 634, 21, 188, 22, 66, 25, 347, 575, 411, 257, 1749, 1805, 2069, 1905, 924, 2027, 889, 893, 351, 1881, 2070, 1636, 1919, 2052, 2221, 2013, 617, 513, 1609, 1527, 430, 2103, 1882, 659, 1683, 2173, 2104, 1568, 2222, 411, 5662, 2113, 45, 560, 1528, 9, 3076, 63, 2113, 45, 560, 411, 15, 26, 2880, 626, 302, 2545, 2634, 58, 2, 348, 63, 1515, 1771, 436]),\n",
              "       list([26, 28103, 25, 5, 127, 9, 7, 1255, 1724, 570, 390, 1090, 934, 2019, 1, 1275, 39, 110, 58, 8, 261, 53, 197, 2, 7, 15, 1693, 3, 52, 105, 63544, 34, 63545, 63546, 26044, 117, 5, 63547, 3, 14628, 40, 7, 97, 2643, 29, 2, 365, 1646, 21, 8, 8136, 6, 1, 103, 39, 413, 58, 8, 127, 10, 5, 929, 40, 7, 319, 2, 1983, 63, 21, 402, 38, 956, 39, 110, 58, 7, 46, 107, 1056, 2, 59, 28, 17653, 34, 1983, 63, 727, 4915, 1654, 3092, 3426, 3938, 1654, 3092, 390, 4916]),\n",
              "       ...,\n",
              "       list([6428, 27, 1, 282, 3969, 5, 262, 50, 215, 109, 64, 659, 1485, 4910, 135, 7472, 311, 7, 24, 25, 5, 292, 13, 22, 118, 2, 25, 460, 32, 1, 3564, 379, 10, 1, 13, 38, 124, 90, 25, 9, 67, 156, 160, 80, 684, 417, 2, 156, 54, 308, 776, 530, 1164, 20759, 242, 70, 2820, 5674, 242, 70, 2657, 412, 12, 14, 1557, 50, 770, 10829, 1622, 1, 598, 641, 1217, 124, 16, 9095, 731, 3, 72, 3, 1, 95, 344, 2, 496, 30, 2, 54, 104, 78, 13, 2, 1672, 1, 2195, 1525, 208, 33, 3085, 678, 2123, 9438, 108, 1953, 15, 412, 716, 151, 94, 159, 5, 80, 109, 156, 80, 427, 331, 14016, 10929, 4, 510, 229, 1, 114, 41, 123, 85, 1, 114, 123, 1, 660, 1, 2374, 416, 4, 2917, 18, 33, 3, 199, 57740, 588, 199, 214, 2901, 800, 3676, 17, 42, 6123, 25, 1064, 2258, 32, 1965, 2851, 1582, 19, 735, 10, 5, 898, 3477]),\n",
              "       list([1477, 6, 129, 4412, 889, 3030, 28, 363, 16513, 665, 50, 116, 10, 5, 1141, 2, 241, 9, 2319, 2926, 76, 20, 12, 80, 856, 1, 1950, 5, 305, 304, 13, 515, 3138, 78, 2, 365, 5900, 21, 5, 2133, 3742, 3, 857, 514, 3, 210, 162, 1924, 89, 510, 73, 99, 27, 331, 14, 103, 901, 3, 2563, 10, 72, 3, 1, 1755, 485, 1, 41258, 242, 70, 530, 3, 104, 3596, 1, 1212, 218, 12, 14, 352, 9, 190, 12, 14, 1073, 628, 38, 133, 10, 462, 4598, 266, 78, 587, 174, 477, 448, 415, 125, 1, 831, 304, 899, 23, 556, 2, 1417, 714, 516, 494, 4, 366, 4, 7562, 27, 12, 14, 2213, 752, 76, 42, 3646, 18, 5, 719, 2, 291, 286, 4713, 2, 120, 28, 50, 1863, 835, 41, 243, 195, 2, 54, 41, 195, 360, 1998, 795, 236, 352, 45, 44, 15, 8, 898, 52, 105, 279, 34, 1778, 2015]),\n",
              "       list([1886, 1403, 2, 3287, 187, 279, 788, 2, 880, 11, 173, 3, 190, 12, 14, 4356, 12, 14, 144, 93, 3, 54, 54, 976, 201, 122, 358, 13, 90, 97, 145, 7, 2, 429, 24, 16, 9001, 28, 1, 442, 3, 1154, 953, 18, 231, 22, 46, 1856, 1128, 241, 30, 53, 611, 6, 1, 945, 20, 500, 633, 69, 393, 17, 1, 2635, 2408, 9, 1954, 1323, 62, 2483, 1, 133, 13, 24, 354, 4, 1230, 1, 5183, 1406, 945, 2153, 9, 1, 4617, 115, 20, 177, 864, 959, 2845, 3, 56, 2486, 262, 50, 2290, 25, 2685, 13, 807, 224, 2690, 15, 35, 9078, 316, 2, 2073, 1, 456, 8142, 4, 20, 12, 293, 200, 486, 13, 90, 100, 67, 115, 33, 36, 29, 271, 11, 38, 98, 183, 901, 110, 2, 52, 2672, 279, 34, 1778, 2015, 119, 1778, 8, 1393, 127, 4, 681, 324, 122, 2, 1, 228, 62, 25, 678, 50, 4695, 363, 1113, 68079, 677, 1422, 323, 2229, 14])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEGZ6wkpJHMf"
      },
      "source": [
        "# all input text are padded into same # of words (256)\n",
        "train_data = tf.keras.preprocessing.sequence.pad_sequences(x_train_assembled,\n",
        "                                                        value=0,\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "test_data = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=0,\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A1mfOYTqwkd"
      },
      "source": [
        "### Building the Model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W3Mumuxu15-"
      },
      "source": [
        "Set up Bi-directional GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBBs7pngJHH8",
        "outputId": "3311acc3-59dd-4c92-c5cf-005d500acce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "vocab_size = len(word_index)+10000 #an estimate of true vocabulary size\n",
        "\n",
        "Sequence_length=256\n",
        "Embedding_size=64\n",
        "Number_neuron=128\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=Embedding_size, input_length=Sequence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(Number_neuron, dropout=0.4,\n",
        "        recurrent_dropout=0.3)),\n",
        "    tf.keras.layers.Dense(Number_neuron, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_19 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_20 (Embedding)     (None, 256, 64)           5188544   \n",
            "_________________________________________________________________\n",
            "bidirectional_15 (Bidirectio (None, 256)               148992    \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 5,370,561\n",
            "Trainable params: 5,370,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHLfXmkRU0XA"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeAZKN8KJHFT"
      },
      "source": [
        "# Shuffle training data for cross validation during training cycle\n",
        "Frac = 0.75 # fraction of training data used for training. Remaining is for cross validation.\n",
        "idx = np.arange(len(train_data))\n",
        "np.random.shuffle(idx) # shuffle then get the top 75%, equivilent to random draw\n",
        "\n",
        "idxs = idx[:round(len(idx)*Frac)] # Select random 75% for training data\n",
        "partial_x_train = train_data[idxs]\n",
        "partial_y_train = y_train_assembled[idxs]\n",
        "\n",
        "x_val = np.delete(train_data, idxs.tolist(), axis=0) # select remaining as cross validation data\n",
        "y_val = np.delete(y_train_assembled, idxs.tolist(), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U775glhuEG-U",
        "outputId": "c6212c10-1ebe-4f64-ca6a-70369501b933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model_fit= model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    #callbacks=[EarlyStopping(monitor='val_loss', patience=3)],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.4226 - val_acc: 0.9187\n",
            "Epoch 2/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.9176\n",
            "Epoch 3/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.4721 - val_acc: 0.9239\n",
            "Epoch 4/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 4.0969e-04 - acc: 1.0000 - val_loss: 0.4569 - val_acc: 0.9218\n",
            "Epoch 5/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.4701e-04 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.9234\n",
            "Epoch 6/40\n",
            "12/12 [==============================] - 19s 2s/step - loss: 1.7295e-04 - acc: 1.0000 - val_loss: 0.5251 - val_acc: 0.9250\n",
            "Epoch 7/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.4224 - val_acc: 0.9203\n",
            "Epoch 8/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 0.0032 - acc: 0.9990 - val_loss: 0.3826 - val_acc: 0.8998\n",
            "Epoch 9/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0055 - acc: 0.9983 - val_loss: 0.5849 - val_acc: 0.9113\n",
            "Epoch 10/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.4883 - val_acc: 0.9208\n",
            "Epoch 11/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 7.0513e-04 - acc: 0.9997 - val_loss: 0.4596 - val_acc: 0.9234\n",
            "Epoch 12/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 6.5292e-04 - acc: 0.9997 - val_loss: 0.4298 - val_acc: 0.9218\n",
            "Epoch 13/40\n",
            "12/12 [==============================] - 19s 2s/step - loss: 4.0558e-04 - acc: 1.0000 - val_loss: 0.4476 - val_acc: 0.9208\n",
            "Epoch 14/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 1.3147e-04 - acc: 1.0000 - val_loss: 0.4579 - val_acc: 0.9208\n",
            "Epoch 15/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 1.2064e-04 - acc: 1.0000 - val_loss: 0.5099 - val_acc: 0.9234\n",
            "Epoch 16/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 1.7084e-04 - acc: 1.0000 - val_loss: 0.4857 - val_acc: 0.9224\n",
            "Epoch 17/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 6.3966e-05 - acc: 1.0000 - val_loss: 0.4736 - val_acc: 0.9224\n",
            "Epoch 18/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 8.0970e-05 - acc: 1.0000 - val_loss: 0.4945 - val_acc: 0.9218\n",
            "Epoch 19/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 3.2279e-04 - acc: 0.9998 - val_loss: 0.5336 - val_acc: 0.9229\n",
            "Epoch 20/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 1.2157e-04 - acc: 1.0000 - val_loss: 0.4974 - val_acc: 0.9218\n",
            "Epoch 21/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 5.3367e-05 - acc: 1.0000 - val_loss: 0.5015 - val_acc: 0.9234\n",
            "Epoch 22/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 3.5466e-05 - acc: 1.0000 - val_loss: 0.5111 - val_acc: 0.9239\n",
            "Epoch 23/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 6.1921e-05 - acc: 1.0000 - val_loss: 0.5203 - val_acc: 0.9276\n",
            "Epoch 24/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 7.2501e-05 - acc: 1.0000 - val_loss: 0.5156 - val_acc: 0.9271\n",
            "Epoch 25/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 3.1123e-05 - acc: 1.0000 - val_loss: 0.4999 - val_acc: 0.9208\n",
            "Epoch 26/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.4893e-05 - acc: 1.0000 - val_loss: 0.5060 - val_acc: 0.9218\n",
            "Epoch 27/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 5.6470e-05 - acc: 1.0000 - val_loss: 0.5200 - val_acc: 0.9244\n",
            "Epoch 28/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 7.0189e-05 - acc: 1.0000 - val_loss: 0.5147 - val_acc: 0.9234\n",
            "Epoch 29/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 3.5298e-05 - acc: 1.0000 - val_loss: 0.5109 - val_acc: 0.9234\n",
            "Epoch 30/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 2.0415e-05 - acc: 1.0000 - val_loss: 0.5201 - val_acc: 0.9255\n",
            "Epoch 31/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 7.2989e-05 - acc: 1.0000 - val_loss: 0.5321 - val_acc: 0.9250\n",
            "Epoch 32/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.2542e-05 - acc: 1.0000 - val_loss: 0.5437 - val_acc: 0.9244\n",
            "Epoch 33/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.1587e-04 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.9250\n",
            "Epoch 34/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 4.3883e-05 - acc: 1.0000 - val_loss: 0.5454 - val_acc: 0.9292\n",
            "Epoch 35/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 2.3463e-05 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.9286\n",
            "Epoch 36/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.7574e-05 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.9276\n",
            "Epoch 37/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 2.2332e-05 - acc: 1.0000 - val_loss: 0.5450 - val_acc: 0.9265\n",
            "Epoch 38/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 2.0035e-05 - acc: 1.0000 - val_loss: 0.5460 - val_acc: 0.9260\n",
            "Epoch 39/40\n",
            "12/12 [==============================] - 18s 2s/step - loss: 1.7560e-05 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.9265\n",
            "Epoch 40/40\n",
            "12/12 [==============================] - 18s 1s/step - loss: 1.8128e-05 - acc: 1.0000 - val_loss: 0.5372 - val_acc: 0.9250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whDpiH_2rS-6"
      },
      "source": [
        "### Model Performance Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDm98aTPD777",
        "outputId": "c73f3d99-8d41-40f9-9138-9ecc5b8b9446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Evaluation metrics (loss & acc) on test data\n",
        "results = model.evaluate(test_data, y_test_array)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 [==============================] - 3s 110ms/step - loss: 0.6801 - acc: 0.9089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFrGECTitHf_"
      },
      "source": [
        "Model performance over epoches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6SpFcLJoitb",
        "outputId": "58dff0e6-0e82-46fd-a26a-6c2c68f1755a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iy_Q7-37Nnp",
        "outputId": "409dd37f-ea23-426e-fd0b-6e9571317b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8deHICCCyi4QVkURK0uIUrEqrsUVtVpFakHbIqhttVW/Wm1/FvVbrdpavy41raIiFdxKtdWqIC6tG1HZBFHUqCwKomyyw+f3x7khk3AnmSQzmUl4Px+PeeTu85mb5H7mnHPvOebuiIiIVNQo2wGIiEhuUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISkzs2fMbGS6t80mMysxs2MycFw3s32i6T+b2a9T2bYG7zPCzJ6raZwilTE9B9GwmdnahNnmwEZgazR/gbtPrPuocoeZlQA/dvepaT6uA73cfWG6tjWz7sDHwC7uviUdcYpUpnG2A5DMcvcWpdOVXQzNrLEuOpIr9PeYG1TFtJMysyFmtsjM/sfMPgfGm1krM/unmS03s6+j6fyEfV40sx9H06PM7D9mdku07cdmdnwNt+1hZi+b2Rozm2pmd5rZQ0niTiXG68zsv9HxnjOztgnrzzWzT8xshZldXcn5GWRmn5tZXsKy08xsdjR9sJm9ZmYrzWypmd1hZk2SHOt+M7s+Yf7yaJ8lZnZ+hW1PNLN3zGy1mX1mZtcmrH45+rnSzNaa2SGl5zZh/8FmNsPMVkU/B6d6bqp5nlub2fjoM3xtZlMS1g0zs5nRZ/jQzIZGy8tV55nZtaW/ZzPrHlW1/cjMPgVeiJY/Gv0eVkV/Iwck7L+rmd0a/T5XRX9ju5rZv8zspxU+z2wzOy3us0pyShA7t72A1kA3YDTh72F8NN8VWA/cUcn+g4AFQFvg98C9ZmY12PZvwJtAG+Ba4NxK3jOVGM8BzgPaA02AywDMrA9wd3T8TtH75RPD3d8AvgGOqnDcv0XTW4FLo89zCHA0cGElcRPFMDSK51igF1Cx/eMb4IfAnsCJwFgzOzVad3j0c093b+Hur1U4dmvgX8Dt0Wf7A/AvM2tT4TPscG5iVHWeJxCqLA+IjvXHKIaDgQeBy6PPcDhQkux8xDgC2B/4bjT/DOE8tQfeBhKrRG8BBgKDCX/HVwDbgAeAH5RuZGb9gM6EcyPV4e567SQvwj/qMdH0EGAT0KyS7fsDXyfMv0ioogIYBSxMWNcccGCv6mxLuPhsAZonrH8IeCjFzxQX4zUJ8xcC/46mfwNMSli3W3QOjkly7OuB+6LploSLd7ck214C/D1h3oF9oun7geuj6fuAGxO22zdx25jj3gb8MZruHm3bOGH9KOA/0fS5wJsV9n8NGFXVuanOeQY6Ei7ErWK2u6c03sr+/qL5a0t/zwmfrWclMewZbbMHIYGtB/rFbNcM+JrQrgMhkdxV1/9vDeGlEsTObbm7byidMbPmZnZPVGRfTajS2DOxmqWCz0sn3H1dNNmimtt2Ar5KWAbwWbKAU4zx84TpdQkxdUo8trt/A6xI9l6E0sLpZtYUOB14290/ieLYN6p2+TyK438JpYmqlIsB+KTC5xtkZtOjqp1VwJgUj1t67E8qLPuE8O25VLJzU04V57kL4Xf2dcyuXYAPU4w3zvZzY2Z5ZnZjVE21mrKSSNvo1SzuvaK/6cnAD8ysETCcUOKRalKC2LlVvIXtl8B+wCB3352yKo1k1UbpsBRobWbNE5Z1qWT72sS4NPHY0Xu2Sbaxu88jXGCPp3z1EoSqqvcI31J3B35VkxgIJahEfwOeBLq4+x7AnxOOW9Uth0sIVUKJugKLU4irosrO82eE39meMft9Buyd5JjfEEqPpfaK2SbxM54DDCNUw+1BKGWUxvAlsKGS93oAGEGo+lvnFarjJDVKEJKoJaHYvjKqz/5/mX7D6Bt5MXCtmTUxs0OAkzMU42PASWb2nahBeRxV/w/8Dfg54QL5aIU4VgNrzaw3MDbFGB4BRplZnyhBVYy/JeHb+YaoPv+chHXLCVU7PZMc+2lgXzM7x8wam9lZQB/gnynGVjGO2PPs7ksJbQN3RY3Zu5hZaQK5FzjPzI42s0Zm1jk6PwAzgbOj7QuBM1KIYSOhlNecUEorjWEbobruD2bWKSptHBKV9ogSwjbgVlR6qDElCEl0G7Ar4dvZ68C/6+h9RxAaelcQ6v0nEy4McWoco7u/C1xEuOgvJdRTL6pit4cJDacvuPuXCcsvI1y81wB/iWJOJYZnos/wArAw+pnoQmCcma0htJk8krDvOuAG4L8W7p76doVjrwBOInz7X0FotD2pQtypquo8nwtsJpSilhHaYHD3NwmN4H8EVgEvUVaq+TXhG//XwG8pXyKL8yChBLcYmBfFkegyYA4wA/gKuIny17QHgQMJbVpSA3pQTnKOmU0G3nP3jJdgpOEysx8Co939O9mOpb5SCUKyzswOMrO9oyqJoYR65ylV7SeSTFR9dyFQlO1Y6jMlCMkFexFuwVxLuId/rLu/k9WIpN4ys+8S2mu+oOpqLKmEqphERCSWShAiIhKrwXTW17ZtW+/evXu2wxARqVfeeuutL929Xdy6BpMgunfvTnFxcbbDEBGpV8ys4tP326mKSUREYilBiIhILCUIERGJpQQhIiKxlCBERCRWxhKEmd1nZsvMbG6S9WZmt5vZwmg4wIKEdSPN7IPoNTJTMVZl4kTo3h0aNQo/J06sao/q7V/b9fVVps9Lbdbn8u+8Pp83xZad2GotUyMREbpHLgDmJll/AqHLYAO+DbwRLW8NfBT9bBVN7zByVcXXwIEDvSYeesi9Wzd3s/DzoYfKljdv7g5lr+bNy9ZXtm8q+6djfbL3Toeqjl/T9XVxXmq6Ppd/5/X5vCm27MSWKqDYk13Hk61Ix4swwEeyBHEPMDxhfgFhKMPhwD3Jtkv2qkmCqOwEd+tWfnnpq1u3qvd1r3r/2qyv7YWsNueltuszeV5quz6Xf+f1+bwptuzElqpcTRD/BL6TMD8NKCT08Z44bu6vgcuSHGM0YbCZ4q5du1bvrHjlJ9gsfp1Z1fu6V71/bdbX9kJWm/NS2/WZPC+1XZ/Lv/P6fN4UW3ZiS1VlCaJeN1K7e5G7F7p7Ybt2sU+KV+rTT5Mv71pxIMhI6fLK9k3cLtn+tVlf1XtffTWsW1d+3bp1YXmpyuouqzp+bdZn8rzUdn0u/87r83lTbNmJLS2SZY50vMjxKqbaVOPU9lt8JqtpqvpmkcvVY7lcJ5zN33l9Pm+KLTuxpYocrWI6kfKN1G9Gy1sDHxMaqFtF062req90t0GUrq9pg2RV+9dmfaYv8HXxT5OJ85KO9bn6O8/2eVFs9TO2VGQlQRDG8l1KGLd2EfAjYAwwJlpvwJ3Ah4RxZQsT9j2fMF7vQuC8VN4v3XcxZXrf2qrNhSyVustc+MPNRQ31c8nOq7IE0WAGDCosLHT15lpm4sTQ5lBa73/DDTBiRFjXvTt8EtN/Y7duUFJSl1GKSLaZ2VvuXhi3rl43UktyI0aEi/22beFnaXKAkCyaNy+/ffPmYbmISCkliJ3QiBFQVBRKDGbhZ1FR+SQiItJgBgyS6hkxQglBRCqnEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKxlCBERCSWEoSIiMRSghARkVhKECIiEksJQkREYmU0QZjZUDNbYGYLzezKmPXdzGyamc02sxfNLD9h3e/N7F0zm29mt5uZZTJWEREpL2MJwszygDuB44E+wHAz61Nhs1uAB929LzAO+F2072DgUKAv8C3gIOCITMUqIiI7ymQJ4mBgobt/5O6bgEnAsArb9AFeiKanJ6x3oBnQBGgK7AJ8kcFYRUSkgkwmiM7AZwnzi6JliWYBp0fTpwEtzayNu79GSBhLo9ez7j6/4huY2WgzKzaz4uXLl6f9A4iI7Myy3Uh9GXCEmb1DqEJaDGw1s32A/YF8QlI5yswOq7izuxe5e6G7F7Zr164u4xYRafAaZ/DYi4EuCfP50bLt3H0JUQnCzFoA33P3lWb2E+B1d18brXsGOAR4JYPxiohIgkyWIGYAvcysh5k1Ac4GnkzcwMzamllpDFcB90XTnxJKFo3NbBdC6WKHKiYREcmcjCUId98CXAw8S7i4P+Lu75rZODM7JdpsCLDAzN4HOgA3RMsfAz4E5hDaKWa5+1OZilVERHZk7p7tGNKisLDQi4uLsx2GiEi9YmZvuXth3LpsN1KLiEiOUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiaUEISIisZQgREQklhKEiIjEUoIQEZFYShAiIhJLCUJERGIpQYiISCwlCBERiZXRBGFmQ81sgZktNLMrY9Z3M7NpZjbbzF40s/yEdV3N7Dkzm29m88yseyZjFRGR8jKWIMwsD7gTOB7oAww3sz4VNrsFeNDd+wLjgN8lrHsQuNnd9wcOBpZlKlYREdlRJksQBwML3f0jd98ETAKGVdimD/BCND29dH2USBq7+/MA7r7W3ddlMFYREamgygRhZiebWU0SSWfgs4T5RdGyRLOA06Pp04CWZtYG2BdYaWZPmNk7ZnZzVCKpGNtoMys2s+Lly5fXIEQREUkmlQv/WcAHZvZ7M+ud5ve/DDjCzN4BjgAWA1uBxsBh0fqDgJ7AqIo7u3uRuxe6e2G7du3SHJqIyM6tygTh7j8ABgAfAveb2WvRN/eWVey6GOiSMJ8fLUs89hJ3P93dBwBXR8tWEkobM6PqqS3AFKAg1Q8lIiK1l1LVkbuvBh4jtCN0JFQHvW1mP61ktxlALzPrYWZNgLOBJxM3MLO2CdVXVwH3Jey7p5mVFguOAualEquIiKRHKm0Qp5jZ34EXgV2Ag939eKAf8Mtk+0Xf/C8GngXmA4+4+7tmNs7MTok2GwIsMLP3gQ7ADdG+WwnVS9PMbA5gwF9q9AlFRKRGzN0r38DsAeBed385Zt3R7j4tU8FVR2FhoRcXF2c7DBGResXM3nL3wrh1jVPY/1pgacLBdgU6uHtJriQHERFJv1TaIB4FtiXMb42WiYhIA5ZKgmgcPegGQDTdJHMhiYhILkglQSxPaFTGzIYBX2YuJBERyQWptEGMASaa2R2Eu4k+A36Y0ahERCTrqkwQ7v4h8G0zaxHNr814VCIiknWplCAwsxOBA4BmZgaAu4/LYFwiIpJlqTwo92dCf0w/JVQxnQl0y3BcIiKSZak0Ug929x8CX7v7b4FDCL2tiohIA5ZKgtgQ/VxnZp2AzYT+mEREpAFLpQ3iKTPbE7gZeBtw1C+SiEiDV2mCiHpanRZ1wf24mf0TaObuq+okOhERyZpKq5jcfRthXOnS+Y1KDiIiO4dU2iCmmdn3rPT+VhER2SmkkiAuIHTOt9HMVpvZGjNbneG4REQky1J5krqqoUVFRKQBqjJBmNnhccvjBhASEZGGI5XbXC9PmG4GHAy8RRgnWkREGqhUqphOTpw3sy7AbRmLSEREckIqjdQVLQL2T3cgIiKSW1Jpg/g/wtPTEBJKf8IT1SIi0oCl0gZRnDC9BXjY3f+boXhERCRHpJIgHgM2uPtWADPLM7Pm7r4us6GJiEg2pfQkNbBrwvyuwNTMhCMiIrkilQTRLHGY0Wi6eeZCEhGRXJBKgvjGzApKZ8xsILA+cyGJiEguSKUN4hLgUTNbQhhydC/CEKQiItKApfKg3Awz6w3sFy1a4O6bMxuWiIhkW5VVTGZ2EbCbu89197lACzO7MPOhiYhINqXSBvGTaEQ5ANz9a+AnmQtJRERyQSoJIi9xsCAzywOapHJwMxtqZgvMbKGZXRmzvpuZTTOz2Wb2opnlV1i/u5ktMrM7Unk/ERFJn1QSxL+ByWZ2tJkdDTwMPFPVTlEiuRM4HugDDDezPhU2uwV40N37AuOA31VYfx2gbsVFRLIglQTxP8ALwJjoNYfyD84lczCw0N0/cvdNwCRgWIVt+kTHBpieuD66nbYD8FwK7yUiImlWZYJw923AG0AJ4aJ/FDA/hWN3Bj5LmF8ULUs0Czg9mj4NaGlmbcysEXArcFkK7yMiIhmQ9DZXM9sXGB69vgQmA7j7kWl8/8uAO8xsFKEqaTGwFbgQeNrdFyU0f8TFOBoYDdC1a9c0hiUiIpU9B/Ee8ApwkrsvBDCzS6tx7MVAl4T5/GjZdu6+hKgEYWYtgO+5+0ozOwQ4LLqdtgXQxMzWuvuVFfYvAooACgsLHRERSZvKEsTpwNnAdDP7N6ENIfnX+R3NAHqZWQ9CYjgbOCdxAzNrC3wVVWNdBdwH4O4jErYZBRRWTA4iIpJZSdsg3H2Ku58N9CY0IF8CtDezu83suKoO7O5bgIuBZwltFo+4+7tmNs7MTok2GwIsMLP3CQ3SN9Tq04iISNqYe+o1M2bWCjgTOMvdj85YVDVQWFjoxcXFVW8oIiLbmdlb7l4Yt65aY1K7+9fuXpRryUFERNKvWglCRER2HkoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrGUIEREJJYShIiIxFKCEBGRWEoQIiISSwlCRERiKUGIiEgsJQgREYmlBCEiIrEqG1FORGSnMHEi3Hcf5OdDz57lX3vtBVadsTQbECUIEdmpPfwwnHsu9OgB778PEyZA4jhqu+4a1vXtC8ccE17dumUv3rqkBCEiO62nngrJ4fDD4ZlnQjLYsAE++QQ++gg+/jj8/PBDeOklmDQp7LfPPnD00SFZHHkktGmT3c+RKdUacjSXachR2RkUF8P//R+0b1++GqRbN2jSJNvR1S8vvAAnnBBKBlOnwu67V769O8yfH7adOhVefBHWrAnVTwUFZaWLQw8Niaa+qGzIUSUIkXpi6lQ49VRo1Ag2bYKNG8vWmUGXLiFZnHACXH559uKsD954I5QAuncPJYOalAA2b4YZM2DaNHj+eXj99bCsaVP4znfKEsaAAZCXl/aPkDZKECL13BNPwPDhsO++8Nxz0KEDLF1aVgVS+pozB2bOhH/8A045JdtR56bZs2HIEGjdGl55BTp2TM9x164NxystYcyeHZa3ahXe71vfKl/q69QpJPuKtmyBzz4r/3t1D1VhBxyQnlgTKUGI1GP33Qc/+QkMGgT/+le44CSzeXOo7li5EubNg5Yt6y7O+uCDD+Cww6BxY/jPf0IJIlO++CJUY5VWR5WUwLZtZeubNg3v37NnSPiLFoVk8MknsHVr2Xa77BJ+bt4MgwfD6NFw5pnQvHl64lSCEKmnbr0VLrsMjjsulCJ2263qfV57LdSD//zn8Mc/Zj7GdNiyJdxNVFJS/lt2+/bpu8X0009Dcli3LnzT7907PcdN1aZNIYbEkkHp64svyqoIK746d4avv4YHH4SiIliwAPbYA37wg5As+vatXVxKEPXUZ5+Fi8Lpp4c/Htl5uMM118D//i98//vh1svqNEJfeCHccw+8+SYMHJi5OGvLHR5/PHzWBQt2XN+8efxFs2fP8O27ssbgzZvLV9Xcemu4EE+fHtoF6iP3kNyKiuCxx0I71KBBcMEFMGpUzZKpEkQ9smVLuN2uqAiefjoUSfv0gVdfDd8apOHbuhUuuihc4EePhrvuqn4j56pV4Rtyx44hSTROww3ta9eG2zx79gxVHc2a1e54U6fCVVeFO7P23z8kw+OOK7vFNO61bl35Y3TqVJYw8vNh+fKybT/9tHxVTatW4bbWQw+tXdy5YsWK8MWhqCich6lTa3YcJYgMWrYs1C+eemrtbjP85BO4997wWrIkPL35ox+F5DByZLgb4qmn0vOPLrln7dqyBucHHwwlxyuvDBfNmlaxPPpoKH3ceiv84he1i++FF8LfY0lJmG/WLFTXlD4L0L9/6klsxoyQGKZNg65d4be/DQ2wVe3vHv7fkiWPxYuhXbvkJY5OnXL7bqKacg9tTpW1TVVGCSJD3OHYY8Mfeo8eMG5cuNMk1T/CzZtDo2NREfz732HZ0KHhW+OJJ5Y1Tt1zD4wZE+qUb7stM5+lurZtC3fT9OgB++1X9+//+uvhW/J3vpNavXyuWL8+JPo5c8pf3JYtK9umUSO48cba36rqDiefHKpU5s2r2dO/a9bAFVfAn/8MvXqF0szGjWV36sydG7Zr3RqOOip8O6+sZPH88yH5tW0bqpXGjAmNtemwbVv8XUFSucoSBO7eIF4DBw70uvbgg+7gftFF7gMGhOkDD3R/6in3bduS7/fRR+6/+pX7XnuFfTp1cv/Nb9xLSpLv8/Ofh23//Of0f47qWrjQ/YgjQjzgfvjh7g895L5+febf++uv3c8/v+y9d9klxHLdde6vvea+eXNm33/TJvf//Mf9n/90X7ky9f3mzHH/6U/d99wzxJ2X596jh/vRR7v/5Cfuv/ud+6RJ7m++6b5iRfriLSlxb97c/aSTKv+bjPP88+5du7qbuf/iF+7ffLPjNkuWhN/9qFHu+fllv5dkrxYt3K+91n316vR8Pqk9oNiTXFezfmFP16uuE8SXX7q3bev+7W+7b90aXpMnu/fqFc7q4MHuL79ctv2mTe6PPeZ+3HHhH65Ro/BP++STqV3UNm92P/5498aN3adNy9znqszWre5/+lO44Oy+u/vdd7vfeKP73nuHz9y6tfsll7i/+25m3v9f/3Lv3Dmcu6uucn/2WfcrrnAvKAjnFEJcp5wS4pw8OfnrscfcX3/dfdmyyi+c27a5z53rfttt4ffVokXZxS4vz/2QQ9yvucb9xRfdN2wov+8337iPHx+2AfcmTdzPOcd9+vTw91BXbr01vP+jj6a2/apVIWmB+377uf/3v6ntt22b+xdfuC9dmvwVl2Qku5QgMuC888LFevbs8ss3bXK/555QKgD3E04IF7EOHcJ8ly7hG9Snn1b/PVeudO/Tx71VK/cFC9LzOVL1/vvuhx1W9pk++6xs3dat7lOnun//++EbPbgfeqj7/fe7L19e+/f+6iv3kSPDcQ84IHzLrmj5cvdHHnEfPdq9Z0+v8ptsxW+1ffu6n3pq+KZ8xx3uf/2r+w9+UFbKA/d99nEfMyYkl2nT3K++2n3QoJCwICTOoUPdb745lCr32CMs793b/Q9/SM+5qInNm0MJt2PHyks969e7P/FE+Btt1Mj98svd162ruzglO5Qg0mz69HDmrrwy+TbffON+003hYp6X5z5sWPgGvGVL7d77ww9DyWXffcOFM9O2bAkXt113DRe8+++v/Bv3smXhAllakjILF6fLLw/f+Kv7DfLJJ8OFLS8vXJArfktP5tNPQ0km2WvmzFAV+Kc/heq7k08OyWfXXcsSQrt27mefHZLFxx8nf6+vv3b/+99DUujdO+zbtGlIMC+/XP2qnUyYMSNc9MeOLVu2dav7W2+Fv9Njj3Vv1izEvv/+oXQlO4fKEkRGG6nNbCjwJyAP+Ku731hhfTfgPqAd8BXwA3dfZGb9gbuB3YGtwA3uPrmy96qrRuoNG6Bfv3A76ty5VXfKtXZt2Kdt2/TF8Mor4e6R0h4oSxuz0+399+G888IttiedFBoqO3dObV/30N/N88+HRvxXXw2N8k2ahIbMY46Bb387eQOle2i8nzABDjwQxo+vm/v53cO98qtXhx47a9LouWRJuH9/zz3TH19tXHIJ3H57uGtozpzwe/nqq7DugAPC7+Too8OtpulqOJbcl5VGakJS+BDoCTQBZgF9KmzzKDAymj4KmBBN7wv0iqY7AUuBPSt7v7oqQfzmN+Fb1nPP1cnbJTV+fIhjzJjMfEPdvNm9W7dQApowofbvsXat+zPPuP/yl+79+qVW9dO4cTjfGzem5SPt9FavDtVHEBqUR40KDcxLlmQ7MskmKilBZPKu+oOBhe7+EYCZTQKGAfMStukDlN6hPR2YAuDu75du4O5LzGwZoZSxMoPxVum99+B3v4MRI8Ltrdk0alS4dfHmm+GHP4RDDknv8Z98Mjyb8fe/h2c8amu33cItvEOHhvlly8K32MS+aSrq2RP23rv27y1By5ahVLdmTbhldWcdJU1Sl8kE0Rn4LGF+ETCowjazgNMJ1VCnAS3NrI27ryjdwMwOJpRAPqz4BmY2GhgN0LVr17QGX9G2beFx9hYt4A9/yOhbpeyXvwwJ4vXX058g7rwzPMR08snpPW6p9u1DdYbUrY4d09d7qTR82X6s5DLgCDN7BzgCWExocwDAzDoCE4Dz3H2H75ruXuTuhe5e2K5duxoH8eGH5YcYjDN+PLz8crggt29f47dKqw4dwj/7O++k97jz5oUnZ8eMaZhPnopIajJZglgMJHYxlx8t287dlxBKEJhZC+B77r4ymt8d+Bdwtbu/nqkgv/wyFLf32qtsgI+jjy7fGLtsWXiq9fDD4fzzMxVJzRQUwNtvp/eYd90VGpN//OP0HldE6pdMJogZQC8z60FIDGcD5yRuYGZtga+i0sFVhDuaMLMmwN+BB939sQzGSJMm8Je/hG4Dnnkm3DUDofOw0mTx8MPwzTehy4tcq7cdMCDEvW5devqHX7Mm9AV01lmhXxsR2XllrIrJ3bcAFwPPAvOBR9z9XTMbZ2alY10NARaY2ftAB+CGaPn3gcOBUWY2M3r1z0Scu+8eOiF7+OFwe+PMmXDLLaHfmnvvDQ20kyeHzsXquv/4VBQUhPaROXPSc7wJE0KSuOii9BxPROovddZXiY0bQwPwe++F5wFycVD4kpLQYd7dd4c2g9pwD/fDN28eetzMtdKSiKRfZc9BqPPoSjRtCkccEV65qlu30M1vOtohXnwR5s8PQ1wqOYhItu9ikloyC+0Q6biT6c47Q7fNZ59d+2OJSP2nBNEAFBTA7DbOqMwAABKzSURBVNmhK4uaWrQIpkwJ7TFVdR8iIjsHJYgGYMCAMCD6/Pk1P8Y994TG7rFj0xeXiNRvShANQEFB+FnTdohNm8KtvieeGBq8RURACaJB6NUr3HlU03aIxx8Pt/jq1lYRSaS7mBqAvLwwaHxNSxB33BG6tj7uuPTGJTuPzZs3s2jRIjZs2JDtUCSJZs2akZ+fzy7VGB9ACaKBGDAAHnig+gO3z5wZxmq49VYN+C41t2jRIlq2bEn37t0x3SOdc9ydFStWsGjRInpUox5Zl4QGoqAgDE60cGH19rvzznDX0nnnZSYu2Tls2LCBNm3aKDnkKDOjTZs21S7hKUE0EAMGhJ/VaYf4+muYODGMb9GqVWbikp2HkkNuq8nvRwmigTjggDD0aHXaIcaPh/Xr1TgtIvGUIBqIJk3gW9+qXgnigQdg0KDQwC1SlyZOhO7dQ7tX9+5hvjZWrFhB//796d+/P3vttRedO3fePr9p06ZK9y0uLuZnP/tZle8xePDg2gVZD6mRugEpKAhPQ7tX3ZfS/Pnh6es//aluYhMpNXEijB4duqiHMLTt6NFhesSImh2zTZs2zJw5E4Brr72WFi1acNlll21fv2XLFho3jr/cFRYWUlgY21ddOa+++mrNgqvHVIJoQAYMgBUrQrcZVZk8OSSRM87IfFwiia6+uiw5lFq3LixPp1GjRjFmzBgGDRrEFVdcwZtvvskhhxzCgAEDGDx4MAsWLADgxRdf5KSTTgJCcjn//PMZMmQIPXv25Pbbb99+vBYtWmzffsiQIZxxxhn07t2bESNGUNor9tNPP03v3r0ZOHAgP/vZz7YfN1FJSQmHHXYYBQUFFBQUlEs8N910EwceeCD9+vXjyiuvBGDhwoUcc8wx9OvXj4KCAj78cIfRlzNGJYgGJPGJ6i5dkm/nDpMmhV5qO3Wqm9hESn36afWW18aiRYt49dVXycvLY/Xq1bzyyis0btyYqVOn8qtf/YrHH398h33ee+89pk+fzpo1a9hvv/0YO3bsDs8OvPPOO7z77rt06tSJQw89lP/+978UFhZywQUX8PLLL9OjRw+GDx8eG1P79u15/vnnadasGR988AHDhw+nuLiYZ555hn/84x+88cYbNG/enK+++gqAESNGcOWVV3LaaaexYcMGtm3bYfTljFGCaED69g2lgnfegWHDkm83axYsWACXXlp3sYmU6to1VCvFLU+3M888k7xoYPVVq1YxcuRIPvjgA8yMzUl6tzzxxBNp2rQpTZs2pX379nzxxRfk5+eX2+bggw/evqx///6UlJTQokULevbsuf05g+HDh1NUVLTD8Tdv3szFF1/MzJkzycvL4/333wdg6tSpnHfeeTSPhoZs3bo1a9asYfHixZx22mlAeNitLqmKqQHZbbcw6l1VdzJNnhyevv7e9+omLpFEN9yw4/C4zZuH5em22267bZ/+9a9/zZFHHsncuXN56qmnkj4T0LRp0+3TeXl5bNmypUbbJPPHP/6RDh06MGvWLIqLi6tsRM8mJYgGpqqxIUqrl445Btq2rbu4REqNGAFFRWGwK7Pws6io5g3UqVq1ahWdO3cG4P7770/78ffbbz8++ugjSkpKAJg8eXLSODp27EijRo2YMGECW7duBeDYY49l/PjxrIsaaL766itatmxJfn4+U6ZMAWDjxo3b19cFJYgGpqAgNFIvXx6//s03wzClGhRIsmnEiPB3uG1b+Jnp5ABwxRVXcNVVVzFgwIBqfeNP1a677spdd93F0KFDGThwIC1btmSPPfbYYbsLL7yQBx54gH79+vHee+9tL+UMHTqUU045hcLCQvr3788tt9wCwIQJE7j99tvp27cvgwcP5vPPP0977MloTOoG5oUX4Oij4dln4zvfu/RSuOuu0HvrnnvWfXzSMM2fP5/9998/22Fk3dq1a2nRogXuzkUXXUSvXr24NIca++J+T5WNSa0SRANT2uVGXDvEtm3wyCNw/PFKDiKZ8Je//IX+/ftzwAEHsGrVKi644IJsh1QruoupgWnVKjyZGtcO8Z//wJIlcNZZdR6WyE7h0ksvzakSQ22pBNEAFRTEJ4hJk0LPrSefXPcxiUj9owTRAA0YAB98AKtXly3bsgUeeywkh+iBUBGRSilBNEClT1TPmlW2bPr0cGeT7l4SkVQpQTRAiV1ulJo0CVq2DA3UIiKpUIJogPbaK7xK2yE2boQnnoBTT4U6flJfpE4ceeSRPPvss+WW3XbbbYwdOzbpPkOGDKH01vgTTjiBlStX7rDNtddeu/15hGSmTJnCvHnzts//5je/YerUqdUJP2cpQTRQBQVlJYjnnoOVK1W9JA3X8OHDmTRpUrllkyZNStphXkVPP/00e9bw3u+KCWLcuHEcc8wxNTpWrtFtrg3UgAHhYbkNG0LfS61bh+41RDLtkksgGpohbfr3h9tuS77+jDPO4JprrmHTpk00adKEkpISlixZwmGHHcbYsWOZMWMG69ev54wzzuC3v/3tDvt3796d4uJi2rZtyw033MADDzxA+/bt6dKlCwMHDgTCMw5FRUVs2rSJffbZhwkTJjBz5kyefPJJXnrpJa6//noef/xxrrvuOk466STOOOMMpk2bxmWXXcaWLVs46KCDuPvuu2natCndu3dn5MiRPPXUU2zevJlHH32U3r17l4uppKSEc889l2+++QaAO+64Y/ugRTfddBMPPfQQjRo14vjjj+fGG29k4cKFjBkzhuXLl5OXl8ejjz7K3nvvXavzrhJEA1VQAFu3hq41/vEPOP30MOqcSEPUunVrDj74YJ555hkglB6+//3vY2bccMMNFBcXM3v2bF566SVmz56d9DhvvfUWkyZNYubMmTz99NPMmDFj+7rTTz+dGTNmMGvWLPbff3/uvfdeBg8ezCmnnMLNN9/MzJkzy12QN2zYwKhRo5g8eTJz5sxhy5Yt3H333dvXt23blrfffpuxY8fGVmOVdgv+9ttvM3ny5O2j3iV2Cz5r1iyuuOIKIHQLftFFFzFr1ixeffVVOnbsWLuTSoZLEGY2FPgTkAf81d1vrLC+G3Af0A74CviBuy+K1o0Erok2vd7dH8hkrA1N6RPV118Pa9eqeknqTmXf9DOptJpp2LBhTJo0iXvvvReARx55hKKiIrZs2cLSpUuZN28effv2jT3GK6+8wmmnnba9y+1TTjll+7q5c+dyzTXXsHLlStauXct3v/vdSuNZsGABPXr0YN999wVg5MiR3HnnnVxyySVASDgAAwcO5Iknnthh/1zoFjxjCcLM8oA7gWOBRcAMM3vS3eclbHYL8KC7P2BmRwG/A841s9bA/wMKAQfeivb9OlPxNjTdu4fuNJ5/Hjp0gCFDsh2RSGYNGzaMSy+9lLfffpt169YxcOBAPv74Y2655RZmzJhBq1atGDVqVNJuvqsyatQopkyZQr9+/bj//vt58cUXaxVvaZfhyboLT+wWfNu2bXU+FgRktorpYGChu3/k7puASUDFYWz6AC9E09MT1n8XeN7dv4qSwvPA0AzG2uCYlZUizjwzjP8g0pC1aNGCI488kvPPP3974/Tq1avZbbfd2GOPPfjiiy+2V0Elc/jhhzNlyhTWr1/PmjVreOqpp7avW7NmDR07dmTz5s1MnDhx+/KWLVuyZs2aHY613377UVJSwsKFC4HQK+sRRxyR8ufJhW7BM5kgOgOfJcwvipYlmgWcHk2fBrQ0szYp7itVKH0eQn0vyc5i+PDhzJo1a3uC6NevHwMGDKB3796cc845HHrooZXuX1BQwFlnnUW/fv04/vjjOeigg7avu+666xg0aBCHHnpouQbls88+m5tvvpkBAwaUGy+6WbNmjB8/njPPPJMDDzyQRo0aMWbMmJQ/Sy50C56x7r7N7AxgqLv/OJo/Fxjk7hcnbNMJuAPoAbwMfA/4FvBjoJm7Xx9t92tgvbvfUuE9RgOjAbp27Trwk7hxDHdi770Hf/sbXHstNNLtCJJB6u67fsil7r4XA10S5vOjZdu5+xJ3P93dBwBXR8tWprJvtG2Ruxe6e2G7du3SHX+917s3jBun5CAiNZPJS8cMoJeZ9TCzJsDZwJOJG5hZWzMrjeEqwh1NAM8Cx5lZKzNrBRwXLRMRkTqSsQTh7luAiwkX9vnAI+7+rpmNM7PSe8eGAAvM7H2gA3BDtO9XwHWEJDMDGBctE5Ec1VBGp2yoavL70ZCjIlJrH3/8MS1btqRNmzaYWbbDkQrcnRUrVrBmzRp69OhRbl1lbRDqakNEai0/P59FixaxfPnybIciSTRr1oz8/Pxq7aMEISK1tssuu+zwzVTqP93fIiIisZQgREQklhKEiIjEajB3MZnZcqCyR6nbAl/WUTjVpdhqRrHVjGKrmYYaWzd3j33SuMEkiKqYWXGyW7myTbHVjGKrGcVWMztjbKpiEhGRWEoQIiISa2dKEEXZDqASiq1mFFvNKLaa2eli22naIEREpHp2phKEiIhUgxKEiIjEavAJwsyGmtkCM1toZldmO56KzKzEzOaY2Uwzy2p3tGZ2n5ktM7O5Cctam9nzZvZB9LNVDsV2rZktjs7dTDM7IQtxdTGz6WY2z8zeNbOfR8uzft4qiS0XzlszM3vTzGZFsf02Wt7DzN6I/l8nR2PJ5Eps95vZxwnnrX9dx5YQY56ZvWNm/4zmM3Pe3L3BvoA84EOgJ9CEMAZ2n2zHVSHGEqBttuOIYjkcKADmJiz7PXBlNH0lcFMOxXYtcFmWz1lHoCCabgm8D/TJhfNWSWy5cN4MaBFN7wK8AXwbeAQ4O1r+Z2BsDsV2P3BGNs9bQoy/AP4G/DOaz8h5a+gliIOBhe7+kbtvAiYBw7IcU85y95eBigMzDQMeiKYfAE6t06AiSWLLOndf6u5vR9NrCINjdSYHzlslsWWdB2uj2V2ilwNHAY9Fy7N13pLFlhPMLB84EfhrNG9k6Lw19ATRGfgsYX4ROfIPksCB58zsLTMbne1gYnRw96XR9OeEkf9yycVmNjuqgspK9VcpM+sODCB848yp81YhNsiB8xZVk8wElgHPE0r7Kz2MRglZ/H+tGJu7l563G6Lz9kcza5qN2IDbgCuAbdF8GzJ03hp6gqgPvuPuBcDxwEVmdni2A0rGQ/k1Z75JAXcDewP9gaXArdkKxMxaAI8Dl7j76sR12T5vMbHlxHlz963u3h/IJ5T2e2cjjjgVYzOzbwFXEWI8CGgN/E9dx2VmJwHL3P2tuni/hp4gFgNdEubzo2U5w90XRz+XAX8n/KPkki/MrCNA9HNZluPZzt2/iP6RtwF/IUvnzsx2IVyAJ7r7E9HinDhvcbHlynkr5e4rgenAIcCeZlY6kFnW/18TYhsaVdm5u28ExpOd83YocIqZlRCqzI8C/kSGzltDTxAzgF5RC38T4GzgySzHtJ2Z7WZmLUungeOAuZXvVeeeBEZG0yOBf2QxlnJKL8CR08jCuYvqf+8F5rv7HxJWZf28JYstR85bOzPbM5reFTiW0EYyHTgj2ixb5y0utvcSEr4R6vjr/Ly5+1Xunu/u3QnXsxfcfQSZOm/Zbo3P9As4gXD3xofA1dmOp0JsPQl3Vs0C3s12fMDDhCqHzYR6zB8R6jenAR8AU4HWORTbBGAOMJtwQe6Yhbi+Q6g+mg3MjF4n5MJ5qyS2XDhvfYF3ohjmAr+JlvcE3gQWAo8CTXMothei8zYXeIjoTqdsvYAhlN3FlJHzpq42REQkVkOvYhIRkRpSghARkVhKECIiEksJQkREYilBiIhILCUIkSqY2daEHjxnWhp7BTaz7ok91IrkksZVbyKy01vvodsFkZ2KShAiNWRhLI/fWxjP400z2yda3t3MXog6dZtmZl2j5R3M7O/ROAOzzGxwdKg8M/tLNPbAc9HTu5jZz6KxHGab2aQsfUzZiSlBiFRt1wpVTGclrFvl7gcCdxB62QT4P+ABd+8LTARuj5bfDrzk7v0IY1u8Gy3vBdzp7gcAK4HvRcuvBAZExxmTqQ8nkoyepBapgpmtdfcWMctLgKPc/aOoU7zP3b2NmX1J6L5ic7R8qbu3NbPlQL6Hzt5Kj9Gd0J10r2j+f4Bd3P16M/s3sBaYAkzxsjEKROqEShAiteNJpqtjY8L0VsraBk8E7iSUNmYk9NYpUieUIERq56yEn69F068SetoEGAG8Ek1PA8bC9gFp9kh2UDNrBHRx9+mEcQf2AHYoxYhkkr6RiFRt12h0sVL/dvfSW11bmdlsQilgeLTsp8B4M7scWA6cFy3/OVBkZj8ilBTGEnqojZMHPBQlEQNu9zA2gUidURuESA1FbRCF7v5ltmMRyQRVMYmISCyVIEREJJZKECIiEksJQkREYilBiIhILCUIERGJpQQhIiKx/j+ZmZxoAcLEmwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COZ9Whynb-z8"
      },
      "source": [
        "Both loss and accuracy over epoches graphs showing the model overfits on training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-Il6Wlhcnip"
      },
      "source": [
        "Model performance- Precision & Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCtNIMp1oi0Z",
        "outputId": "e37b86b2-5753-4494-8e7e-f6a582149841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "predicted = model.predict(test_data)\n",
        "\n",
        "predicted[predicted > 0.5] = 1\n",
        "predicted[predicted <= 0.5] = 0\n",
        "predictedf = predicted.flatten().astype(int)\n",
        "\n",
        "import pandas as pd\n",
        "df3 = pd.DataFrame(data=predictedf, columns=['predicted'])\n",
        "refdf = pd.DataFrame(data=y_test_array, columns=['actual'])\n",
        "\n",
        "y_actu = pd.Series(refdf['actual'], name='ACTUAL')\n",
        "y_pred = pd.Series(df3['predicted'], name='PREDICTED')\n",
        "predicted_results = y_pred.tolist()\n",
        "truth = y_actu.tolist()\n",
        "\n",
        "dl_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
        "\n",
        "dl_confusion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Predicted</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>All</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Actual</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>179</td>\n",
              "      <td>59</td>\n",
              "      <td>238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>639</td>\n",
              "      <td>662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All</th>\n",
              "      <td>202</td>\n",
              "      <td>698</td>\n",
              "      <td>900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Predicted    0    1  All\n",
              "Actual                  \n",
              "0          179   59  238\n",
              "1           23  639  662\n",
              "All        202  698  900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWkmGn0-ojUv",
        "outputId": "6bce0dbe-0d8f-436c-8809-41daeb221a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        " from sklearn.metrics import classification_report\n",
        "report = classification_report(truth, predicted_results)\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.81       238\n",
            "           1       0.92      0.97      0.94       662\n",
            "\n",
            "    accuracy                           0.91       900\n",
            "   macro avg       0.90      0.86      0.88       900\n",
            "weighted avg       0.91      0.91      0.91       900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0zbivbSt41W"
      },
      "source": [
        "Model produces high precision and recall for Spam messages but relative low recall for Ham messages (75% Ham text are correctly classified). \n",
        "\n",
        "To improve the performance:\n",
        "*   Use simpler approch for data balancing (as shown in Text Classification Solution 1)\n",
        "*   Try different 'temperature' values at the step of generating new text\n",
        "*   Use L1/L2 generalization to prevent overfit\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFaArjPz9mBa"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}